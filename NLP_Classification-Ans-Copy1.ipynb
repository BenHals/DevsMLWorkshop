{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae1f032",
   "metadata": {},
   "source": [
    "# Machine Learning for text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75999cc",
   "metadata": {},
   "source": [
    "Lets set the stage! After a year full of COVID disruptions the university has made all exams online. Celebrations all around! But wait, what about the cheating you say? Fortunately (or unfortunately), the uni has predicted this, and hired a crack team of Designated Exam Validators (or DEVs for short) to check for plagarism. And you've just been hired! And of course, you're going to use ML to do all your work for you!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44ce829",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e179f",
   "metadata": {},
   "source": [
    "Given a sentence, we need to find the probability a sentence came from each possible source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b67f7",
   "metadata": {},
   "source": [
    "For example, given the text \"The University of Auckland began as a constituent college of the University of New Zealand, founded on 23 May 1883 as Auckland University College\" the probability for \"Wikipedia\" = 0.9 and \"Twitter\" = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bdadea",
   "metadata": {},
   "source": [
    "We need to build a machine learning classifier to do this for us!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecad3e6",
   "metadata": {},
   "source": [
    "# 1) Collect data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77686a31",
   "metadata": {},
   "source": [
    "First, we need some data from each source. This will allow us to find patterns, i.e., learn what makes *wikipedia* sentences different to *twitter* sentences\n",
    "\n",
    "This is normally the *most important part of ML*, but we've taken care of it! In the github repo there is a data folder containing some datasets from different sources.\n",
    "\n",
    "First we will just load this in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956eb744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in some libraries\n",
    "# The pathlib library makes handling filepaths easier, letting us open data files.\n",
    "import pathlib\n",
    "\n",
    "# Set the folder containing our data\n",
    "data_path = pathlib.Path('data')\n",
    "\n",
    "# Setup availiable filenames\n",
    "chess_filename = \"chess.txt\"\n",
    "music_filename = \"music.txt\"\n",
    "angry_filename = \"angry_topical_chat.txt\"\n",
    "happy_filename = \"happy_topical_chat.txt\"\n",
    "disgusted_filename = \"disgusted_topical_chat.txt\"\n",
    "trumpspeech_filename = \"trumpSpeech.txt\"\n",
    "wallstreetbets_filename = \"wallstreetbets_comments.txt\"\n",
    "javascript_filename = \"javascript.txt\"\n",
    "shakespeare_filename = \"shakespeare.txt\"\n",
    "\n",
    "# Just a helper function, don't worry about this one!\n",
    "def get_file_or_cache(path):\n",
    "    cache = None\n",
    "    def get():\n",
    "        nonlocal cache\n",
    "        if not cache:\n",
    "            with path.open('r', encoding='utf8') as f:\n",
    "                cache = f.readlines()\n",
    "        return cache\n",
    "    return (get, path.stem)\n",
    "\n",
    "# Construct a list of possible files and their names\n",
    "data_files = [get_file_or_cache(data_path / x) for x in [chess_filename, music_filename, happy_filename, trumpspeech_filename, wallstreetbets_filename, javascript_filename, shakespeare_filename]]\n",
    "\n",
    "# Construct dataset of sentences and labels from every source\n",
    "# Note! Rather than using the actual names for the datasets, we give each one\n",
    "# its own numeric ID.\n",
    "# We record these so we can swap between human readable name and ID.\n",
    "X = []\n",
    "Y = []\n",
    "source_IDs = {}\n",
    "ID_to_source = {}\n",
    "source_ID = 0\n",
    "for source_constructor, source in data_files:\n",
    "    source_IDs[source] = source_ID\n",
    "    ID_to_source[source_ID] = source\n",
    "    lines = source_constructor()\n",
    "    for line in lines:\n",
    "        X.append(line)\n",
    "        Y.append(source_ID)\n",
    "    source_ID += 1\n",
    "\n",
    "observations = list(zip(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f3407b",
   "metadata": {},
   "source": [
    "Now we have our data loaded into X, a list of sentences, and Y, a list of the sources each sentence came from.\n",
    "Lets check out some sample lines from each source!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c569533d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation 0\n",
      "X0 =  I don't know how to process this. My brain... It can't... What? Yay?\n",
      "\n",
      "Y0 = 4 Source name: wallstreetbets_comments\n",
      "-----------\n",
      "Observation 1\n",
      "X1 =  [removed]\n",
      "\n",
      "Y1 = 4 Source name: wallstreetbets_comments\n",
      "-----------\n",
      "Observation 2\n",
      "X2 =  [deleted]\n",
      "\n",
      "Y2 = 4 Source name: wallstreetbets_comments\n",
      "-----------\n",
      "Observation 3\n",
      "X3 =  [removed]\n",
      "\n",
      "Y3 = 4 Source name: wallstreetbets_comments\n",
      "-----------\n",
      "Observation 4\n",
      "X4 =  I fnally got back in after I forgot to delete a stop loss on RH. If anyone is wondering, Chase and Fidelity are not restricting trading. Trade at your own risk and always be careful.\n",
      "\n",
      "Y4 = 4 Source name: wallstreetbets_comments\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "inspect_index = 100000\n",
    "for index, (line, source) in enumerate(observations[inspect_index:inspect_index+5]):\n",
    "    print(\"Observation\", index)\n",
    "    print(\"X{} = \".format(index), line)\n",
    "    # Source is stored as a number, representing the source (explained later!)\n",
    "    print(\"Y{} =\".format(index), source, \"Source name:\", ID_to_source[source])\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad506406",
   "metadata": {},
   "source": [
    "# How do we *actually* predict?\n",
    "\n",
    "The goal is to learn a model which can tell the difference between classes. For example, consider sentences from Wikipedia (W) or Twitter (T). If we show our model a new input sentence (X) where we do NOT know the origin, our model should be able to tell where the sentence came from. \n",
    "\n",
    "Formally, the $i^{th}$ input is called $x_{i}$ and its true class is called $y_{i}$.\n",
    "For us, $x_{i}$ is the $i^{th}$ sentence we need to label and $y_{i}$ is where this sentence actually came from.\n",
    "Our model predicts some label, $\\hat y_{i}$, for this sentence (so *wikipedia* or *twitter*).\n",
    "We want to train it so that *our* label, $\\hat y_{n}$, is close to the *true* label, $y_{i}$.\n",
    "\n",
    "There are many, many different ways to do this prediction, and we will look at a simple one called Naive Bayes.\n",
    "\n",
    "Lets true a manual version to get the idea:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406e7dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where my name is to go?\n",
      "\n",
      "Where did this sentence come from? javascript or shakespeare or trumpSpeechshakespeare\n",
      "You were Wrong !\n",
      "Your predicted label (y^) was: shakespeare. The true label (y) was trumpSpeech\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Pick two random labels to choose from\n",
    "g, label_opt1 = random.choice(data_files)\n",
    "g, label_opt2 = random.choice(data_files)\n",
    "\n",
    "# Select a random observations from a random source\n",
    "source_gen, true_label = random.choice(data_files)\n",
    "\n",
    "# Shuffle labels\n",
    "label_options = [label_opt1, label_opt2, true_label]\n",
    "random.shuffle(label_options)\n",
    "\n",
    "lines = source_gen()\n",
    "line = random.choice(lines)\n",
    "print(line)\n",
    "predicted_label = input(\"Where did this sentence come from? {} or {} or {}\".format(*label_options))\n",
    "print(\"You were\", \"Right\" if true_label == predicted_label else \"Wrong\", \"!\")\n",
    "print(\"Your predicted label (y^) was: {}. The true label (y) was {}\".format(predicted_label, true_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5cb081",
   "metadata": {},
   "source": [
    "## Using a model to make a prediction\n",
    " \n",
    " How can we *train the computer* to predict a class for us? \n",
    " Lets think of a simple example: We are given a sentence ($x$), and need to predict where it came from ($\\hat y$), Wikipedia (W) or Twitter (T). We start by asking a friend where they think it came from, and they say it has a 70% chance of being from Wikipedia and 30% from Twitter. \n",
    "\n",
    " In mathmatical terms we can rewrite the \"_probability of this specific sentence $x$ being from Wikipedia, $\\hat y = W$, is 0.7_\" as $p(\\hat y = W | x) = 0.7$. Similarly, we can write $p(\\hat y = T | x) = 0.3$ for the sentence being from twitter.\n",
    "\n",
    " Now it is pretty easy to make a prediction, Wikipedia has a 70% chance and Twitter only has a 30% chance so we should predict Wikipedia! \n",
    "\n",
    " ### But how did our friend come up with $p(\\hat y| x)$ in the first place?\n",
    " This is basically what the computer needs to do, find the probability of a sentence coming from each source.\n",
    " This is what Naive Bayes solves!\n",
    "\n",
    " ## Naive Bayes - Probability theory (spooky)\n",
    "\n",
    " Note: Naive Bayes is pretty simple, and is quite intuitive when you wrap your head around it, but if this is your first introduction to probability it can be quite confusing! If you don't understand at first don't get discoraged! I find that drawing diagrams and thinking about it from a few directions helps really understand.\n",
    "\n",
    " The end goal of a model is to calculate $p(y = C|X=x)$. In plain english, this can be read as calculate the _probability that the true class of the input is C given what we know about the sentence_. For a concrete example, lets use the sentence \"The University of Auckland was founded on 23 May 1883\". We want to predict the probability that $y = Wikipedia$ or $y = Twitter$ given that the sentence $x$ = \"The University of Auckland was founded on 23 May 1883\". This can be difficult to calculate!\n",
    "\n",
    " Instead of calculating this directly, _Bayes Theorum_ gives us a way to swap things around.\n",
    "\n",
    " $$ p(y=C|X=x) = p(X=x|y=C)p(y=C)$$\n",
    " \n",
    " ## Intuition\n",
    " Instead of directly trying to work out the probability of wikipedia or twitter, lets look at indivdual words. If we see the words \"follow me!\" we can say twitter has a pretty high probability. On the other hand, if we see the words \"Auckland[1][2]\" we could say wikipedia has a high probability. How did we do this?\n",
    " \n",
    " We looked at the probability of each word (or few words) coming from each source! This is the $p(x=X|y=C)$ in the formula!\n",
    " \n",
    "Lets see if we can use this to do some machine learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b45336",
   "metadata": {},
   "source": [
    "# Exercise 1: Calculate word probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0867bedb",
   "metadata": {},
   "source": [
    "We need to *learn* 2 things from our data.\n",
    "1. What is the probability of seeing each word overall?\n",
    "    1. This is $p(x=X)$, or the *probability* that a word is X\n",
    "    2. e.g p('and') is high, it occurs a lot! But p('founded') is low, it doesn't occur too often.\n",
    "2. What is the probability of seeing each word *from each source*?\n",
    "    1. This is $p(x=X|y=Y)$, or the *probability* that a word is X if we *know* it is from e.g wikipedia\n",
    "    2. e.g. p('founded'|Twitter) might be pretty low, its an uncommon word on twitter. But p('founded'|Wikipedia) is high, it occurs all the time on wikipedia!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef9ceaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6}\n"
     ]
    }
   ],
   "source": [
    "def fit_NB_model(X, Y):\n",
    "    # fill word probabilities so it contains every word, and the probability of each\n",
    "    # word_probabilities = {\n",
    "    #       'and': 0.75,\n",
    "    #       'founded': 0.01,\n",
    "    #       ....\n",
    "    #}\n",
    "    word_probabilities = {}\n",
    "    # fill word_probs_by_source so it contains a dict for each source\n",
    "    # each containing each word and probability only in that source\n",
    "    # word_probs_by_source = {\n",
    "    #       'Twitter': {\n",
    "    #              'founded': 0.001,\n",
    "    #               ...,\n",
    "    #        },\n",
    "    #       'Wikipedia': {\n",
    "    #              'founded': 0.05,\n",
    "    #              ...,\n",
    "    #       }\n",
    "    #}\n",
    "    word_probs_by_source = {}\n",
    "    sources = set(Y)\n",
    "\n",
    "    for x, y in zip(X, Y):\n",
    "        words = x.split()\n",
    "        for word in words:\n",
    "            # Check word is in dict, else add it\n",
    "            if word not in word_probabilities:\n",
    "                word_probabilities[word] = 0\n",
    "            word_probabilities[word] += 1\n",
    "\n",
    "            # For each source, check word is in dict else add it\n",
    "            for s in sources:\n",
    "                if s not in word_probs_by_source:\n",
    "                    word_probs_by_source[s] = {}\n",
    "                if word not in word_probs_by_source[s]:\n",
    "                    word_probs_by_source[s][word] = 1\n",
    "\n",
    "            # Increment counter\n",
    "            word_probs_by_source[y][word] += 1\n",
    "\n",
    "    # Convert counts to probabilities, taking into account initial 1s\n",
    "    for source in sources:\n",
    "        # Get total number of words in each source\n",
    "        source_total = sum(word_probs_by_source[source].values())\n",
    "        for word in word_probabilities:\n",
    "            source_word_probability = word_probs_by_source[source][word] / source_total\n",
    "            word_probs_by_source[source][word] = source_word_probability\n",
    "    return word_probs_by_source\n",
    "\n",
    "NB_model = fit_NB_model(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2172d19c",
   "metadata": {},
   "source": [
    "Lets check the output but showing the most likely words for each source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90df3d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chess\n",
      "[('16.', 0.0016418199832438306), ('d4', 0.00164715634288601), ('15.', 0.0016596078487177617), ('14.', 0.0016827320738338721), ('13.', 0.0016969623662130167), ('12.', 0.0017111926585921615), ('11.', 0.0017147502316869478), ('10.', 0.001718307804781734), ('9.', 0.0017272017375186996), ('8.', 0.0017414320298978442), ('7.', 0.0017414320298978442), ('6.', 0.0017449896029926304), ('5.', 0.001755662322276989), ('4.', 0.0017609986819191684), ('3.', 0.0017627774684665614), ('2.', 0.0017681138281087408), ('Nf6', 0.001771671401203527), ('1.', 0.0017805653339404925), ('Nf3', 0.001844601649646644), ('O-O', 0.002561452628246063)]\n",
      "music\n",
      "[('z', 0.0010849852796859666), ('G', 0.001088125613346418), ('F2', 0.001110107948969578), ('E2', 0.0012011776251226692), ('f2', 0.0012922473012757605), ('A', 0.001348773307163886), ('d', 0.0015026496565260059), ('c2', 0.0017224730127576055), ('e2', 0.0018512266928361139), ('g2', 0.0019203140333660452), ('D2', 0.0022249263984298333), (':|', 0.0026582924435721296), ('B2', 0.0027493621197252206), ('<li><a', 0.003234543670264966), ('\\\\', 0.003261236506378803), ('||', 0.003835917566241413), ('A2', 0.004325809617271835), ('G2', 0.0047874386653581945), ('d2', 0.004809421000981354), ('|', 0.05634543670264966)]\n",
      "happy_topical_chat\n",
      "[('are', 0.0031218483676428684), ('would', 0.0031354639056948934), ('on', 0.003314410977235793), ('they', 0.0038094330392701293), ('with', 0.003931000343306066), ('like', 0.004402681482965503), ('for', 0.004587463785100128), ('have', 0.005044556848275252), ('it', 0.0057097731359599), ('was', 0.00583814820902185), ('you', 0.006580195032857211), ('in', 0.00726097193545846), ('and', 0.007588717387139347), ('is', 0.007847412610127821), ('that', 0.00873339512194173), ('of', 0.009572695789005842), ('to', 0.012933788610991434), ('a', 0.014590021561177044), ('the', 0.019564555642327595), ('I', 0.021772217883620215)]\n",
      "trumpSpeech\n",
      "[('was', 0.0034310416649723807), ('going', 0.003511463763519271), ('our', 0.0037319468202096215), ('We', 0.004059960547990757), ('for', 0.004466589136149191), ('is', 0.0045533365682896565), ('they', 0.004580445140833552), ('it', 0.004681650478330763), ('And', 0.005029543825977422), ('we', 0.0059376810061979235), ('have', 0.005961175102402632), ('that', 0.006347020451610746), ('in', 0.006981361049137902), ('you', 0.008009679567636341), ('I', 0.011052165026146218), ('of', 0.011072044646011742), ('a', 0.012431087749545705), ('and', 0.014282603254293771), ('to', 0.01578803264956477), ('the', 0.021562158601414524)]\n",
      "wallstreetbets_comments\n",
      "[('at', 0.0050937522661495165), ('my', 0.0051253097394619905), ('have', 0.005379077607757121), ('are', 0.005388561200773305), ('be', 0.005510948603749404), ('[removed]', 0.0065198066884020805), ('this', 0.007399900471326397), ('that', 0.00769127569123743), ('on', 0.008478168646244077), ('it', 0.008659092709561448), ('for', 0.008999848017246405), ('in', 0.010291497035028224), ('you', 0.011019444554132554), ('of', 0.011621080424874778), ('is', 0.012646861817754611), ('and', 0.01600004774498553), ('I', 0.017008905829638207), ('a', 0.019215558063257365), ('to', 0.021944543708776517), ('the', 0.028761530230056433)]\n",
      "javascript\n",
      "[('&&', 2.006809774501475e-05), (\"'\", 2.229788638334972e-05), ('||', 2.229788638334972e-05), ('break;', 2.4527675021684695e-05), ('case', 3.121704093668961e-05), ('function()', 3.3446829575024585e-05), ('new', 3.3446829575024585e-05), ('},', 4.01361954900295e-05), (':', 5.3514927320039336e-05), ('true,', 6.020429323504425e-05), ('function', 6.46638705117142e-05), ('+', 6.689365915004917e-05), ('if', 7.358302506505408e-05), ('};', 7.358302506505408e-05), ('});', 7.581281370338905e-05), ('return', 8.250217961839397e-05), ('var', 0.00011371922055508358), ('}', 0.00015831499332178304), ('=', 0.00029879167753688626), ('{', 0.0003054810434518912)]\n",
      "shakespeare\n",
      "[('have', 9.691672650540311e-05), ('he', 0.0001035246851307715), ('it', 0.0001057273380058943), ('me', 0.00011013264375613989), ('his', 0.00011894325525663109), ('And', 0.0001255512138819995), ('with', 0.00012775386675712227), ('your', 0.00012995651963224508), ('is', 0.00013656447825761346), ('in', 0.00014978039550835027), ('not', 0.00014978039550835027), ('that', 0.00016519896563420985), ('you', 0.00018282018863519223), ('my', 0.00022026528751227978), ('a', 0.00025330508063912174), ('of', 0.0003039660967669461), ('to', 0.0003105740553923145), ('and', 0.00036564037727038445), ('I', 0.00038766690602161244), ('the', 0.000491191591152384)]\n"
     ]
    }
   ],
   "source": [
    "for gen, source in data_files:\n",
    "    word_probs = NB_model[source_IDs[source]].items()\n",
    "    print(source)\n",
    "    print(sorted(word_probs, key = lambda x: x[1])[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4e7c2f",
   "metadata": {},
   "source": [
    "Now we can make predictions for single words! Lets write a function which takes a word an returns the most likely source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4a45cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_probabilities(model, word):\n",
    "    \"\"\" Returns a list of tuples giving\n",
    "    the ID of a source and the probability of word\n",
    "    coming from that source.\n",
    "    \"\"\"\n",
    "    source_probs = []\n",
    "    for source in model:\n",
    "        source_word_probability = model[source][word]\n",
    "        source_probs.append((source_word_probability, source))\n",
    "    return source_probs\n",
    "\n",
    "def predict_single_word(model, word):\n",
    "    \"\"\" Return the source ID word is most likely\n",
    "    to have come from.\n",
    "    \"\"\"\n",
    "    source_probs = get_word_probabilities(model, word)\n",
    "    return sorted(source_probs)[-1][1]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f714e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pred_games_played = 0\n",
    "word_pred_human_correct = 0\n",
    "word_pred_ML_correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5102ce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word is thou\n",
      "Where did this word come from? shakespeare or happy_topical_chat or wallstreetbets_commentsshakespeare\n",
      "[(1.7787865473930993e-06, 0), (1.5701668302257114e-06, 1), (9.725384322874979e-07, 2), (9.036190847965185e-07, 3), (3.7607351615902056e-06, 4), (2.229788638334972e-06, 5), (8.810611500491191e-05, 6)]\n",
      "You were Right !\n",
      "The computer was Right !\n",
      "Your predicted label (y^) was: shakespeare. The computer predicted shakespeare. The true label (y) was shakespeare\n",
      "Your score: 0.7142857142857143 AI score: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "s, label_opt1 = random.choice(data_files)\n",
    "s, label_opt2 = random.choice(data_files)\n",
    "source_gen, true_label = random.choice(data_files)\n",
    "label_options = [label_opt1, label_opt2, true_label]\n",
    "random.shuffle(label_options)\n",
    "lines = source_gen()\n",
    "line = random.choice(lines)\n",
    "word = random.choice(line.split())\n",
    "print(\"Word is\", word)\n",
    "predicted_label = input(\"Where did this word come from? {} or {} or {}\".format(*label_options))\n",
    "ML_predicted_label_ID = predict_single_word(NB_model, word)\n",
    "ML_predicted_label = ID_to_source[ML_predicted_label_ID]\n",
    "print(\"You were\", \"Right\" if true_label == predicted_label else \"Wrong\", \"!\")\n",
    "print(\"The computer was\", \"Right\" if true_label == ML_predicted_label else \"Wrong\", \"!\")\n",
    "print(\"Your predicted label (y^) was: {}. The computer predicted {}. The true label (y) was {}\".format(predicted_label, ML_predicted_label, true_label))\n",
    "word_pred_games_played += 1\n",
    "word_pred_human_correct += (true_label == predicted_label)\n",
    "word_pred_ML_correct += (true_label == ML_predicted_label)\n",
    "print(\"Your score:\", str(word_pred_human_correct / word_pred_games_played), \"AI score:\", str(word_pred_ML_correct / word_pred_games_played))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8823c3ac",
   "metadata": {},
   "source": [
    "## Predicting Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86fc5e6",
   "metadata": {},
   "source": [
    "Now that we can classify the source of individual words, how can we upgrade to sentences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99fa5b9",
   "metadata": {},
   "source": [
    "Lets think about probability a little bit. What is the probability of a heads when a coin is flipped? \n",
    "$$p(H) = \\frac{1}{2}$$\n",
    "Now what is the probability of flipping two heads in a row?\n",
    "$$ p(H) \\times p(H) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}$$\n",
    "\n",
    "We can check this is correct, as there are four possible options, HH, HT, TH, TT, and all are equally likely.\n",
    "\n",
    "Can we do something similar with a sentence? We have the probability of each word coming from each source, can we just multiply them all together to get the probability of the sentence coming from a source?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ba165",
   "metadata": {},
   "source": [
    "### Yes! (Kind of)\n",
    "\n",
    "It turns out that yes, we can! If we make some assumptions...\n",
    "\n",
    "If we assume that all words are independant from each other, this works! This is actually exactly how Naive Bayes works!\n",
    "(Though this may not be so realistic...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da8b13",
   "metadata": {},
   "source": [
    "So, lets put all of our intuition together!\n",
    "1. Firstly, we want to predict the probability of a label (wikipedia, twitter, etc,) given some sentence (\"Follow me please!!!\", \"Auckland was founded...\").\n",
    "    1. In statistics, this can be written p(y=Y|x=X)\n",
    "2. This is *hard* to calculate, so we use bayes rule to flip it around. We predict the probability of the sentence we have coming from each of the sources!\n",
    "    1. This is now: p(x=X|y=Y)\n",
    "3. The probability of the sentence coming from a source can be thought of as the product of each *word* coming from that source!\n",
    "    1. p(Follow me please|Twitter) = p(Follow|Twitter) x p(me|Twitter) x p(please|Twitter)\n",
    "4. Once probabilities are calculated, we can take the most likely label as our prediction!\n",
    "    1. If p(Follow me please|Twitter) = 0.2 and p(Follow me please|Wikipedia) = 0.001, we can predict the sentence \"Follow me please\" is from Twitter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "67ba2ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_sentence_probs(model, sentence):\n",
    "    \"\"\" Returns a list of tuples giving\n",
    "    the ID of a source and the probability of sentence\n",
    "    coming from that source.\n",
    "    \"\"\"\n",
    "    source_probs = {}\n",
    "    for word in sentence.split():\n",
    "#         print(word)\n",
    "        source_probabilities = get_word_probabilities(model, word)\n",
    "#         print({ID_to_source[k]:v for v,k in source_probabilities})\n",
    "        for prob, s_ID in source_probabilities:\n",
    "            if s_ID not in source_probs:\n",
    "                source_probs[s_ID] = 1\n",
    "            source_probs[s_ID] += math.log(prob)\n",
    "#         print({ID_to_source[k]:v for k,v in source_probs.items()})\n",
    "    if len(source_probs.items()) < 1:\n",
    "        for source in model:\n",
    "            source_probs[source] = 1\n",
    "    return source_probs.items()\n",
    "def predict_sentence(model, sentence):\n",
    "    source_probs = get_sentence_probs(model, sentence)\n",
    "#     print(sorted(source_probs, key= lambda x: x[1]))\n",
    "    return sorted(source_probs, key= lambda x: x[1])[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b51b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_pred_games_played = 0\n",
    "sent_pred_human_correct = 0\n",
    "sent_pred_ML_correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c652acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line is: B2A2 G3G | AGFD F2dc | B2AG ^FGAF | G4 G2 ||\n",
      "\n",
      "Where did this word come from? wallstreetbets_comments or happy_topical_chat or musicchess\n",
      "You were Wrong !\n",
      "The computer was Right !\n",
      "Your predicted label (y^) was: chess. The computer predicted music. The true label (y) was music\n",
      "Your score: 0.75 AI score: 0.875\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "s, label_opt1 = random.choice(data_files)\n",
    "s, label_opt2 = random.choice(data_files)\n",
    "source_gen, true_label = random.choice(data_files)\n",
    "label_options = [label_opt1, label_opt2, true_label]\n",
    "random.shuffle(label_options)\n",
    "lines = source_gen()\n",
    "line = random.choice(lines)\n",
    "print(\"Line is:\", line)\n",
    "predicted_label = input(\"Where did this word come from? {} or {} or {}\".format(*label_options))\n",
    "ML_predicted_label_ID = predict_sentence(NB_model, line)\n",
    "ML_predicted_label = ID_to_source[ML_predicted_label_ID]\n",
    "print(\"You were\", \"Right\" if true_label == predicted_label else \"Wrong\", \"!\")\n",
    "print(\"The computer was\", \"Right\" if true_label == ML_predicted_label else \"Wrong\", \"!\")\n",
    "print(\"Your predicted label (y^) was: {}. The computer predicted {}. The true label (y) was {}\".format(predicted_label, ML_predicted_label, true_label))\n",
    "sent_pred_games_played += 1\n",
    "sent_pred_human_correct += (true_label == predicted_label)\n",
    "sent_pred_ML_correct += (true_label == ML_predicted_label)\n",
    "print(\"Your score:\", str(sent_pred_human_correct / sent_pred_games_played), \"AI score:\", str(sent_pred_ML_correct / sent_pred_games_played))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607f9eaa",
   "metadata": {},
   "source": [
    "## Evaluating\n",
    "\n",
    "So, after playing the ML algorithm, it seems pretty good!\n",
    "The next step is to test *how good*. Evaluation is an important part of machine learning, to test how good our models actually are. This is required for two things:\n",
    "1. Making sure we can actually put it into critical decision making roles\n",
    "2. Making sure we understand *what* its decisions are based on\n",
    "3. Making sure any changes we make actually are improving it!\n",
    "\n",
    "Lets look at the most basic form of evaluation, how well the predicted labels match the known labels. This is called *accuracy*!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a900187",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_right = 0\n",
    "num_wrong = 0\n",
    "for X, Y in observations:\n",
    "    ML_predicted_label_ID = predict_sentence(NB_model, X)\n",
    "    num_right += (ML_predicted_label_ID == Y)\n",
    "    num_wrong += (ML_predicted_label_ID != Y)\n",
    "accuracy = num_right / (num_right + num_wrong)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29aa86d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
